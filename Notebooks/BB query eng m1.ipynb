{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 6993140,
     "sourceType": "datasetVersion",
     "datasetId": 4016175
    }
   ],
   "dockerImageVersionId": 30587,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install -q qdrant-client\n",
    "!pip install -q sentence-transformers"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:16:38.812057Z",
     "iopub.execute_input": "2023-11-18T04:16:38.812547Z",
     "iopub.status.idle": "2023-11-18T04:17:32.197746Z",
     "shell.execute_reply.started": "2023-11-18T04:16:38.812512Z",
     "shell.execute_reply": "2023-11-18T04:17:32.196433Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.1 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.1 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.1 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.1 which is incompatible.\ngoogle-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.1 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.1 which is incompatible.\nkfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.0.1 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.1 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.1 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.1 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.1 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0m",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q torch"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:26:00.562591Z",
     "iopub.execute_input": "2023-11-18T04:26:00.563017Z",
     "iopub.status.idle": "2023-11-18T04:26:15.065835Z",
     "shell.execute_reply.started": "2023-11-18T04:26:00.562981Z",
     "shell.execute_reply": "2023-11-18T04:26:15.064108Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from tqdm.auto import tqdm\n",
    "# from typing import List\n",
    "import torch"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:26:38.845345Z",
     "iopub.execute_input": "2023-11-18T04:26:38.845721Z",
     "iopub.status.idle": "2023-11-18T04:26:38.852411Z",
     "shell.execute_reply.started": "2023-11-18T04:26:38.845691Z",
     "shell.execute_reply": "2023-11-18T04:26:38.851286Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import numpy as np"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-11-18T04:12:15.733217Z",
     "iopub.execute_input": "2023-11-18T04:12:15.733608Z",
     "iopub.status.idle": "2023-11-18T04:12:15.768509Z",
     "shell.execute_reply.started": "2023-11-18T04:12:15.733572Z",
     "shell.execute_reply": "2023-11-18T04:12:15.767409Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "VECTOR_SPACE_PATH = \"/kaggle/input/chaabi/space.pkl\"\n",
    "with open(VECTOR_SPACE_PATH, 'rb') as file:\n",
    "    vs = pickle.load(file)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:13:51.567847Z",
     "iopub.execute_input": "2023-11-18T04:13:51.568290Z",
     "iopub.status.idle": "2023-11-18T04:13:53.909312Z",
     "shell.execute_reply.started": "2023-11-18T04:13:51.568253Z",
     "shell.execute_reply": "2023-11-18T04:13:53.907929Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vs[\"payload\"][0]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:14:09.048425Z",
     "iopub.execute_input": "2023-11-18T04:14:09.048844Z",
     "iopub.status.idle": "2023-11-18T04:14:09.057451Z",
     "shell.execute_reply.started": "2023-11-18T04:14:09.048809Z",
     "shell.execute_reply": "2023-11-18T04:14:09.056276Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "execution_count": 3,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'id': 0,\n 'product': 'Garlic Oil - Vegetarian Capsule 500 mg',\n 'story': 'Garlic Oil - Vegetarian Capsule 500 mg is of category Beauty & Hygiene and sub category is Hair Care. Garlic Oil - Vegetarian Capsule 500 mg is type Hair Oil & Serum. brand of Garlic Oil - Vegetarian Capsule 500 mg is Sri Sri Ayurveda , with rating 4.1. sale price of Garlic Oil - Vegetarian Capsule 500 mg is 220.0 with market price 220.0, description of Garlic Oil - Vegetarian Capsule 500 mg is This Product contains Garlic Oil that is known to help proper digestion, maintain proper cholesterol levels, support cardiovascular and also build immunity.  For Beauty tips, tricks & more visit https://bigbasket.blog/'}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "client = QdrantClient(\":memory:\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:18:15.508782Z",
     "iopub.execute_input": "2023-11-18T04:18:15.509732Z",
     "iopub.status.idle": "2023-11-18T04:18:15.516537Z",
     "shell.execute_reply.started": "2023-11-18T04:18:15.509665Z",
     "shell.execute_reply": "2023-11-18T04:18:15.515177Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "collection_name = \"extractive-question-answering\"\n",
    "collection_name = \"qdrant-space\"\n",
    "\n",
    "collections = client.get_collections()\n",
    "if collection_name not in [c.name for c in collections.collections]:\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=384,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    )\n",
    "print(client.get_collections())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:18:15.519254Z",
     "iopub.execute_input": "2023-11-18T04:18:15.519736Z",
     "iopub.status.idle": "2023-11-18T04:18:15.535174Z",
     "shell.execute_reply.started": "2023-11-18T04:18:15.519693Z",
     "shell.execute_reply": "2023-11-18T04:18:15.533877Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "collections=[CollectionDescription(name='qdrant-space')]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    " \n",
    "total_records = len(vs[\"payload\"]) # total records data\n",
    "_payload = vs[\"payload\"]\n",
    "_emb = vs[\"emb\"]\n",
    "ids = list(range(0,total_records))\n",
    "\n",
    "batch_size = 2  # specify batch size according to your RAM and compute, higher batch size = more RAM usage\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=models.Batch(ids=ids, vectors=_emb, payloads=_payload),\n",
    ")\n",
    "\n",
    "\n",
    "collection_vector_count = client.get_collection(collection_name=collection_name).vectors_count\n",
    "print(f\"Vector count in collection: {collection_vector_count}\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:19:57.424184Z",
     "iopub.execute_input": "2023-11-18T04:19:57.424674Z",
     "iopub.status.idle": "2023-11-18T04:22:02.056670Z",
     "shell.execute_reply.started": "2023-11-18T04:19:57.424636Z",
     "shell.execute_reply": "2023-11-18T04:22:02.055400Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": "Vector count in collection: 27555\nCPU times: user 2min 4s, sys: 478 ms, total: 2min 4s\nWall time: 2min 4s\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    retriever = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\", device=device)\n",
    "# retriever = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\", device=device)\n",
    "retriever\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:26:44.239142Z",
     "iopub.execute_input": "2023-11-18T04:26:44.239523Z",
     "iopub.status.idle": "2023-11-18T04:26:54.326311Z",
     "shell.execute_reply.started": "2023-11-18T04:26:44.239495Z",
     "shell.execute_reply": "2023-11-18T04:26:54.325368Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading .gitattributes:   0%|          | 0.00/737 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14b9e67bf2874cde9a9a8b577abde728"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading 1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97b0a392cb6c45c480474ce787fd0194"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading README.md:   0%|          | 0.00/11.5k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2426ecb50f7f41bea04595b78291e2c3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de81a02471b34f7faefec5216f78af31"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2aad86659504457982f0a77372c96b21"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading data_config.json:   0%|          | 0.00/25.5k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fca9c8c1091540ffb58a90168e80bce9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52dead4c546c4665888f9bca2b5f581b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89cc485f34a84d46a4005538a136c488"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a02908905d744e1883c8c0b54702a35"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9d28a9cddc74a2c9c40a54cd1dcc4f5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading tokenizer_config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50423c5c9eb741c297c6f8b6ebbae918"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading train_script.py:   0%|          | 0.00/13.8k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54b17c0e390746e9aa4af85913196de1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1dabea4a94cf4ca0af71d5825f7b83d4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fbf2fc347334b55b9e8faf86a60ba7a"
      }
     },
     "metadata": {}
    },
    {
     "execution_count": 20,
     "output_type": "execute_result",
     "data": {
      "text/plain": "SentenceTransformer(\n  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n  (2): Normalize()\n)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "# load the reader model into a question-answering pipeline\n",
    "reader = pipeline(\"question-answering\", model=model_name, tokenizer=model_name)\n",
    "print(reader.model, reader)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:22:05.784039Z",
     "iopub.execute_input": "2023-11-18T04:22:05.784474Z",
     "iopub.status.idle": "2023-11-18T04:22:38.137439Z",
     "shell.execute_reply.started": "2023-11-18T04:22:05.784442Z",
     "shell.execute_reply": "2023-11-18T04:22:38.136478Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79019196a10a48c3b593eae01d14c228"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49f4d2f3ad414c8ea50bf5d658afabc5"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "729f8e20b88f4ea0807aaf6b6ac31be8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0b4854418cf4b9c960e0893303eb31e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86bfdb6543944665821e9bdcf327fdbc"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "BertForQuestionAnswering(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n      (position_embeddings): Embedding(512, 1024)\n      (token_type_embeddings): Embedding(2, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n) <transformers.pipelines.question_answering.QuestionAnsweringPipeline object at 0x7aed1dea60b0>\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def find_close_contexts(question: str, top_k: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    will return contexts contexts close to query \n",
    "\n",
    "    Args:\n",
    "        question (str): What do we want to know?\n",
    "        top_k (int): top k results will be added \n",
    "\n",
    "    Returns:\n",
    "        context (List[str]):\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoded_query = retriever.encode(question).tolist() \n",
    "        result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=encoded_query,\n",
    "            limit=top_k,\n",
    "        )  # search qdrant collection for context passage with the answer\n",
    "\n",
    "        context = [\n",
    "            [context.payload[\"product\"], context.payload[\"story\"]] for context in result\n",
    "        ] \n",
    "        return context\n",
    "    except Exception as e:\n",
    "        print({e})"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:24:25.858583Z",
     "iopub.execute_input": "2023-11-18T04:24:25.858976Z",
     "iopub.status.idle": "2023-11-18T04:24:25.867205Z",
     "shell.execute_reply.started": "2023-11-18T04:24:25.858946Z",
     "shell.execute_reply": "2023-11-18T04:24:25.865801Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "question = \"what is price of Garlic Oil - Vegetarian Capsule 500 mg\"\n",
    "context = find_close_contexts(question, top_k=1)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T04:28:36.947377Z",
     "iopub.execute_input": "2023-11-18T04:28:36.947773Z",
     "iopub.status.idle": "2023-11-18T04:28:37.061234Z",
     "shell.execute_reply.started": "2023-11-18T04:28:36.947743Z",
     "shell.execute_reply": "2023-11-18T04:28:37.059433Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "842d58b6c7784bd9ae0448f07da3333c"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def tell_me(question: str, context: List[str]):\n",
    "    \"\"\"\n",
    "    Extract the answer from the context for a given question\n",
    "\n",
    "    Args:\n",
    "        question (str): _description_\n",
    "        context (list[str]): _description_\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for c in context:\n",
    "        answer = reader(question=question, context=c[1] )\n",
    "        answer[\"product\"] = c[0]\n",
    "        results.append(answer)\n",
    "        print()\n",
    "\n",
    "    sorted_result = sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
    "    for i in range(len(sorted_result)):\n",
    "        _out = sorted_result[i][\"answer\"] \n",
    "        _prod = sorted_result[i][\"product\"]\n",
    "        _sco = sorted_result[i][\"score\"]\n",
    "#         print(f\"{i+1}\", end=\" \")\n",
    "        print(f\"QUERY INPUT: {question}\")\n",
    "        print(f\"OUTPUT: {_out} \\nPREDICTION SCORE {_sco}\\n\\nReferred Product: {_prod}\\n\\n  \")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T05:00:32.341339Z",
     "iopub.execute_input": "2023-11-18T05:00:32.341730Z",
     "iopub.status.idle": "2023-11-18T05:00:32.350968Z",
     "shell.execute_reply.started": "2023-11-18T05:00:32.341700Z",
     "shell.execute_reply": "2023-11-18T05:00:32.349392Z"
    },
    "trusted": true
   },
   "execution_count": 96,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "queries = []\n",
    "queries.append(\"suggest me one product for cleaning vegetables\")\n",
    "queries.append(\"what is the rating of product Vegetable & Fruit Wash with 100% Natural Action\")\n",
    "queries.append(\"give me soap brand name\")\n",
    "queries.append(\"\")\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T05:05:55.771203Z",
     "iopub.execute_input": "2023-11-18T05:05:55.771631Z",
     "iopub.status.idle": "2023-11-18T05:05:55.776836Z",
     "shell.execute_reply.started": "2023-11-18T05:05:55.771595Z",
     "shell.execute_reply": "2023-11-18T05:05:55.776040Z"
    },
    "trusted": true
   },
   "execution_count": 107,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for q in queries:\n",
    "    c = find_close_contexts(q, top_k=1)\n",
    "    tell_me(q,c)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-18T05:06:01.946150Z",
     "iopub.execute_input": "2023-11-18T05:06:01.947168Z",
     "iopub.status.idle": "2023-11-18T05:06:08.827336Z",
     "shell.execute_reply.started": "2023-11-18T05:06:01.947126Z",
     "shell.execute_reply": "2023-11-18T05:06:08.826105Z"
    },
    "trusted": true
   },
   "execution_count": 108,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06f990a39e20445789fab3ff947213fc"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "\nQUERY INPUT: suggest me one product for cleaning vegetables\nOUTPUT: Vegetable & Fruit Wash \nPREDICTION SCORE 0.003299231640994549\n\nReferred Product: Vegetable & Fruit Wash with 100% Natural Action\n\n  \n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77ec44dfd0d24adeacb2ba5fbed0b6a6"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "\nQUERY INPUT: what is the rating of product Vegetable & Fruit Wash with 100% Natural Action\nOUTPUT: 4.3 \nPREDICTION SCORE 0.9139595627784729\n\nReferred Product: Vegetable & Fruit Wash with 100% Natural Action\n\n  \n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d968f5fc65a4d858574d66406ab21dc"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "\nQUERY INPUT: give me soap brand name\nOUTPUT: Nyassa \nPREDICTION SCORE 0.7516050338745117\n\nReferred Product: Oudh Golab Middle Eastern Handmade Soap\n\n  \n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
