{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7002429,"sourceType":"datasetVersion","datasetId":4016175}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **BigBasket Product's Query Engine Notebook 3**\nNote book is aimed to integrating vector dd qdrant llm model \n\n**It Contains**\n\n**1. Important imports**\n1. qdrant space \n2. bert model \n3. st encoder model \n\n**2. searching closest context from vector db and returning respose from context**","metadata":{}},{"cell_type":"code","source":"!pip install -q qdrant-client\n!pip install -q sentence-transformers\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-19T15:24:50.866114Z","iopub.execute_input":"2023-11-19T15:24:50.866561Z","iopub.status.idle":"2023-11-19T15:25:19.632649Z","shell.execute_reply.started":"2023-11-19T15:24:50.866508Z","shell.execute_reply":"2023-11-19T15:25:19.630738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nfrom sentence_transformers import SentenceTransformer\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:25:19.635648Z","iopub.execute_input":"2023-11-19T15:25:19.636056Z","iopub.status.idle":"2023-11-19T15:25:19.642834Z","shell.execute_reply.started":"2023-11-19T15:25:19.636019Z","shell.execute_reply":"2023-11-19T15:25:19.641633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VECTOR_SPACE_PATH = \"/kaggle/input/chaabi/space.pkl\"\nBERT_MODEL_PATH = \"/kaggle/input/chaabi/bert-question-answering.pkl\"\nENC_PATH  = \"/kaggle/input/chaabi/encodermodel.pkl\"\nQDRANT_PATH  = \"/kaggle/input/chaabi/qdrant_space_client.pkl\"\n\n\n# with open(VECTOR_SPACE_PATH, 'rb') as file:\n#     vs = pickle.load(file)\n# bert llm\nwith open(BERT_MODEL_PATH, 'rb') as file:\n    bert = pickle.load(file)\n\n\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:25:19.644386Z","iopub.execute_input":"2023-11-19T15:25:19.644770Z","iopub.status.idle":"2023-11-19T15:25:21.447511Z","shell.execute_reply.started":"2023-11-19T15:25:19.644736Z","shell.execute_reply":"2023-11-19T15:25:21.446133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# qdrant clinet to interact qdrant space containing all vectors \n\nwith open(QDRANT_PATH, 'rb') as file:\n    qdrant_client = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:25:21.451396Z","iopub.execute_input":"2023-11-19T15:25:21.451789Z","iopub.status.idle":"2023-11-19T15:25:21.579652Z","shell.execute_reply.started":"2023-11-19T15:25:21.451756Z","shell.execute_reply":"2023-11-19T15:25:21.578246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sentence transformer encoder \n\nwith open(ENC_PATH, 'rb') as file:\n    st_encoder = pickle.load(file)\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:25:21.583095Z","iopub.execute_input":"2023-11-19T15:25:21.583984Z","iopub.status.idle":"2023-11-19T15:25:21.743514Z","shell.execute_reply.started":"2023-11-19T15:25:21.583937Z","shell.execute_reply":"2023-11-19T15:25:21.741964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"collection_name = \"qdrant-space\"\ndef find_close_contexts(question: str, top_k: int) -> list[str]:\n    \"\"\"\n    will return contexts contexts close to query \n\n    Args:\n        question (str): What do we want to know?\n        top_k (int): top k results will be added \n\n    Returns:\n        context (List[str]):\n    \"\"\"\n    try:\n        encoded_query = st_encoder.encode(question).tolist() \n        result = qdrant_client.search(\n            collection_name=collection_name,\n            query_vector=encoded_query,\n            limit=top_k,\n        )  # search qdrant collection for context passage with the answer\n\n        context = [\n            [context.payload[\"product\"], context.payload[\"story\"]] for context in result\n        ] \n        return context\n    except Exception as e:\n        print({e})","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:25:21.745688Z","iopub.execute_input":"2023-11-19T15:25:21.746109Z","iopub.status.idle":"2023-11-19T15:25:21.754006Z","shell.execute_reply.started":"2023-11-19T15:25:21.746071Z","shell.execute_reply":"2023-11-19T15:25:21.752924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tell_me(question: str, context: list[str]):\n    \"\"\"\n    Extract the answer from the context for a given question\n\n    Args:\n        question (str): _description_\n        context (list[str]): _description_\n    \"\"\"\n    results = []\n    for c in context:\n        answer = bert(question=question, context=c[1] )\n        answer[\"product\"] = c[0]\n        results.append(answer)\n        print()\n\n    sorted_result = sorted(results, key=lambda x: x[\"score\"], reverse=True)\n    for i in range(len(sorted_result)):\n        _out = sorted_result[i][\"answer\"] \n        _prod = sorted_result[i][\"product\"]\n        _sco = sorted_result[i][\"score\"]\n#         print(f\"{i+1}\", end=\" \")\n        print(f\"QUERY INPUT: {question}\")\n        print(f\"OUTPUT: {_out} \\nPREDICTION SCORE {_sco}\\n\\nReferred Product: {_prod}\\n\\n\")\n        return question,_out,_sco,_prod\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:25:21.755927Z","iopub.execute_input":"2023-11-19T15:25:21.756369Z","iopub.status.idle":"2023-11-19T15:25:21.772459Z","shell.execute_reply.started":"2023-11-19T15:25:21.756337Z","shell.execute_reply":"2023-11-19T15:25:21.771066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries = []\nqueries.append(\"suggest me one product for cleaning vegetables\")\nqueries.append(\"what is the rating of product Vegetable & Fruit Wash with 100% Natural Action\")\nqueries.append(\"what is most loved beauty product\")\nqueries.append(\"price of dove soap\")\nqueries.append(\"what is most loved beauty product\")\nqueries.append(\"suggest one Tea Product\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:25:21.773839Z","iopub.execute_input":"2023-11-19T15:25:21.774162Z","iopub.status.idle":"2023-11-19T15:25:21.787735Z","shell.execute_reply.started":"2023-11-19T15:25:21.774135Z","shell.execute_reply":"2023-11-19T15:25:21.786488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"result.txt\",\"w\") as result:\n    for q in queries:\n        \n        c = find_close_contexts(q, top_k=1)\n        _ques,_out,_sco,_prod = tell_me(q,c)\n        result.write(f\"QUERY INPUT: {_ques}\\nOUTPUT: {_out} \\nPREDICTION SCORE {_sco}\\n\\nReferred Product: {_prod}\\n\\n\")\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:25:21.789260Z","iopub.execute_input":"2023-11-19T15:25:21.790216Z","iopub.status.idle":"2023-11-19T15:25:38.313187Z","shell.execute_reply.started":"2023-11-19T15:25:21.790162Z","shell.execute_reply":"2023-11-19T15:25:38.311940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}