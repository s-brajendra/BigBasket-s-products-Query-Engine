{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7002429,"sourceType":"datasetVersion","datasetId":4016175}],"dockerImageVersionId":30589,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### **BigBasket Product Query Engine  Notebook 1**\n**It contains**\n1. smooth data transformation \n2. extracted important meta data,  encoding done using sentence encoder and stored in dict object along with meta data  \n3. returns space.pkl which will use to store context in vector db(qdrant) file containg vector representation of context and important meta data","metadata":{}},{"cell_type":"code","source":"!pip install -q qdrant-client\n!pip install -q sentence-transformers\n!pip install -q torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-17T22:52:27.743723Z","iopub.execute_input":"2023-11-17T22:52:27.743982Z","iopub.status.idle":"2023-11-17T22:52:50.257838Z","shell.execute_reply.started":"2023-11-17T22:52:27.743957Z","shell.execute_reply":"2023-11-17T22:52:50.256878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport sys\nimport json\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom transformers import pipeline\nfrom sentence_transformers import SentenceTransformer\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.http import models\nfrom tqdm.auto import tqdm\nfrom typing import List\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T22:55:02.929953Z","iopub.execute_input":"2023-11-17T22:55:02.930379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CSV_PATH =  \"/kaggle/input/chaabi/bigBasketProducts.csv\"\ndf = pd.read_csv(CSV_PATH).drop(columns = [\"index\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\n    \nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    retriever = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\", device=device)\n# retriever = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\", device=device)\nretriever","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class make_embedding_ds(torch.utils.data.IterableDataset):\n    def __init__(self, csv = df):\n        \"\"\"\n        will compute embedding using sentence encoder\n        \n        \"\"\"\n        super(make_embedding_ds).__init__()\n        self.csv = csv\n        self.total_row = csv.shape[0]\n        self.col = csv.columns.to_list()\n\n    def __iter__(self):\n        for row_no in range(self.total_row):\n            \n            #testing: make comment it later\n       \n            \n            \n            row = self.csv.iloc[row_no].to_dict()\n            product_name = row[self.col[0]]\n            story = f\"{row[ self.col[0] ]} is of category {row[self.col[1]]} and sub category is {row[self.col[2]]}. {row[self.col[0]]} is type {row[self.col[6]]}. brand of {row[self.col[0]]} is {row[self.col[3]]}, with rating {row[self.col[7]]}. sale price of {row[self.col[0]]} is {row[self.col[4]]} with market price {row[self.col[5]]}, description of {row[self.col[0]]} is {row[self.col[8]]}\"\n            emb = retriever.encode(story)\n            \n            \n            yield row_no,product_name,story,emb\n    \n\nds = make_embedding_ds(df)\n\n\ndataloader = torch.utils.data.DataLoader(ds, num_workers=1,batch_size=128)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T22:54:42.002568Z","iopub.execute_input":"2023-11-17T22:54:42.002892Z","iopub.status.idle":"2023-11-17T22:54:42.052085Z","shell.execute_reply.started":"2023-11-17T22:54:42.002862Z","shell.execute_reply":"2023-11-17T22:54:42.051150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"json_emb = {\n    \"payload\":[],\n    \"emb\": []\n}\nbatch_no = 1\nfor row,product_name,story,emb in dataloader:\n    \n    _batch_len = len(row)\n    \n    \n    \n    print(f\"batch no-{batch_no} competed\")\n    batch_no += 1\n    \n    for index in range(_batch_len):\n        \n        temp = {}\n        temp[\"id\"] = row[index].item()\n        temp[\"product\"] = product_name[index]\n        temp[\"story\"] = story[index]\n        \n        json_emb[\"payload\"].append(temp)\n        json_emb[\"emb\"].append(emb[index].numpy().tolist())\n        \n    \n\n    \n#     json_emb[\"payload\"].append(batch[0])\n#     json_emb[\"emb\"].append(batch[1][0])\n\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T22:54:48.379957Z","iopub.execute_input":"2023-11-17T22:54:48.380315Z","iopub.status.idle":"2023-11-17T22:54:48.403007Z","shell.execute_reply.started":"2023-11-17T22:54:48.380284Z","shell.execute_reply":"2023-11-17T22:54:48.402130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.getsizeof(json_emb)/1024","metadata":{"execution":{"iopub.status.busy":"2023-11-17T22:54:48.938115Z","iopub.execute_input":"2023-11-17T22:54:48.938438Z","iopub.status.idle":"2023-11-17T22:54:48.954514Z","shell.execute_reply.started":"2023-11-17T22:54:48.938396Z","shell.execute_reply":"2023-11-17T22:54:48.953630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# Deserialize the data from the pickle file\nwith open('space.pkl', 'wb') as file:\n    pickle.dump(json_emb, file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}